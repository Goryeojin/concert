## 부하 테스트 대상 API 선정
> 부하 테스트를 위해 다음 4개의 API를 선정했습니다. 선정된 API들은 실제 서비스 운영 시 트래픽이 집중될 가능성이 높은 작업을 기준으로 선정되었습니다.   

1. `POST /api/v1/queue/tokens`: 대기열 토큰 생성 및 인입
- 대기열 시스템 기반의 예약 시스템에서 부하가 가장 많이 예상되는 구간입니다. 유저들이 특정 시점에 몰리면서 대기열에 인입할 때, 시스템은 모든 요청을 처리해야 하므로 이 API 요청에 대한 부하 테스트는 매우 중요합니다. 대기열 인입 시 시스템의 최대 처리 능력을 평가하는 데 적합합니다.   

2. `GET /api/v1/queue/status`: 대기열 토큰 정보 조회   
- 대기열 인입 후, 유저들은 대기 상태를 확인하기 위해 지속적으로 이 API를 polling 합니다. 다수의 사용자가 동시에 반복적으로 조회 요청을 보낼 경우, 시스템에 상당한 부하가 발생할 수 있습니다. 이 API 부하 테스트는 대기열 관리 시스템의 안정성을 평가하는 데 필수적입니다.

3. `GET /api/v1/concert/{concertId}/schedules`: 예약 가능 일정 조회
- 예약 가능한 날짜를 조회하는 과정에서 많은 데이터가 관련될 수 있습니다. 이 API는 좌석 조회와 마찬가지로, 많은 사용자가 동시에 요청을 보낼 경우, 시스템의 성능을 저하시키는 요인이 될 수 있습니다.

4. `GET /api/v1/concert/{concertId}/schedules/{scheduleId}/seats`: 예약 가능 좌석 조회
- 활성열에 인입된 유저들이 예약 진행 전, 좌석 정보를 조회하게 됩니다. 특정 시점에 많은 사용자가 동시에 좌석 조회를 시도할 경우, API는 실시간 데이터 조회와 관련된 부하를 처리해야 합니다.

## 테스트 환경 설정

### 장비 및 시스템 환경
- 운영 체제: macOS (MacBook Air)
- 프로세서: Apple M2
- 메모리(RAM): 16GB
- Docker: Docker Desktop for Mac
  - Docker Engine: 27.3.1

### Docker 기반 서비스 설정
- Kafka: 7.7.0-ccs

### 테스트 및 모니터링 툴
- Prometheus: 2.53.1
- Grafana: 11.1.1
- K6: v0.55.0

## 테스트 시나리오 및 수행 결과 분석
### 1. `POST /api/v1/queue/tokens`: 대기열 토큰 생성 및 인입
> 이 테스트는 대규모 유저가 동시에 대기열에 인입할 때 시스템의 처리 능력을 평가합니다. 목표는 대기열 생성 과정에서의 최대 처리량을 확인하고, 시스템이 고부하 상태에서도 안정적으로 동작하는지 평가하는 것입니다.

#### 테스트 
- 다수의 유저가 동시에 대기열에 인입하려고 시도합니다.
- 각 유저는 고유한 요청을 보내며, 서버는 이를 처리하여 대기열 토큰을 발급합니다.
- 발급된 토큰이 정상적으로 응답되었는지 확인합니다.

#### 부하 조건
- 유저 수: 초당 20명에서 50명까지 유저 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 대기열 토큰 생성은 트래픽이 몰릴 때 시스템에 가장 큰 부하를 발생시킬 수 있는 작업입니다. 트래픽이 증가하는 상황에서 서버의 처리 능력을 평가하기 위해 초당 유저 수를 점진적으로 증가시켜 부하를 가합니다. 이 설정은 서버가 트래픽 급증 시 안정적으로 작동하는지 확인하는 데 적합합니다.
- 예상 트래픽: 목표 TPS는 100 이상으로 설정하며, 초당 최대 100개의 대기열 토큰 생성 요청이 발생할 수 있는 상황을 시뮬레이션하여 서버의 응답 성능을 평가합니다.

#### 성능 지표 분석
```text
     execution: local
        script: api-queue-token-test.js
        output: -

     scenarios: (100.00%) 1 scenario, 50 max VUs, 1m30s max duration (incl. graceful stop):
              * default: Up to 50 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


     ✗ status is 201
      ↳  99% — ✓ 2838 / ✗ 15
     ✗ response time < 500ms
      ↳  98% — ✓ 2817 / ✗ 36

     checks.........................: 99.10% 5655 out of 5706
     data_received..................: 580 kB 9.6 kB/s
     data_sent......................: 472 kB 7.8 kB/s
     http_req_blocked...............: avg=40.24µs  min=1µs      med=7µs      max=50.17ms p(90)=15µs     p(95)=20µs    
     http_req_connecting............: avg=10.44µs  min=0s       med=0s       max=1.76ms  p(90)=0s       p(95)=0s      
   ✓ http_req_duration..............: avg=64.06ms  min=969µs    med=4.71ms   max=5.31s   p(90)=10.39ms  p(95)=15.33ms 
       { expected_response:true }...: avg=64.06ms  min=969µs    med=4.71ms   max=5.31s   p(90)=10.39ms  p(95)=15.33ms 
   ✓ http_req_failed................: 0.00%  0 out of 2853
     http_req_receiving.............: avg=57.97µs  min=5µs      med=46µs     max=865µs   p(90)=114µs    p(95)=139µs   
     http_req_sending...............: avg=40.21µs  min=2µs      med=24µs     max=24.81ms p(90)=56µs     p(95)=70µs    
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s      p(90)=0s       p(95)=0s      
     http_req_waiting...............: avg=63.96ms  min=957µs    med=4.59ms   max=5.31s   p(90)=10.31ms  p(95)=15.3ms  
     http_reqs......................: 2853   47.158402/s
     iteration_duration.............: avg=564.89ms min=501.08ms med=505.62ms max=5.81s   p(90)=511.31ms p(95)=516.77ms
     iterations.....................: 2853   47.158402/s
     vus............................: 21     min=1            max=50
     vus_max........................: 50     min=50           max=50
```
- 평균 요청 처리 속도: 약 47.16 requests/sec
- 평균 응답 시간: 약 64.06ms
- 50번째 백분위수 응답 시간: 약 4.71ms
- 95번째 백분위수 응답 시간: 약 15.33ms
- 최대 응답 시간: 약 5.31s

테스트 결과에 따르면 시스템은 초당 약 47건의 요청을 처리할 수 있으며, 대부분의 요청은 15ms 이하의 빠른 시간 내에 처리되었습니다. 
일부 요청에서 응답 시간이 길어졌지만, 전체적인 성능은 안정적입니다. 시스템은 예상 트래픽에 대해 높은 안정성을 보이고 있습니다.

### 2. `GET /api/v1/queue/status`: 대기열 토큰 정보 조회
> 유저들이 지속적으로 대기열 상태를 확인하는 상황을 시뮬레이션하여, 시스템의 응답 성능과 안정성을 평가하는 것입니다. 특히, 대량의 polling 요청이 있을 때 서버의 성능을 분석합니다.

#### 테스트 
- 여러 유저가 대기열 상태를 지속적으로 확인하기 위해 polling 요청을 보냅니다.
- 서버는 각 유저의 대기열 상태를 반환합니다.
- 응답이 200 OK 상태인지 확인합니다.

#### 부하 조건
- 유저 수: 초당 200명씩 polling 요청
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 대기열 토큰 조회 API는 유저들이 대기 상태를 확인하기 위해 빈번하게 요청을 보내는 작업입니다. 지속적이고 반복적인 부하를 통해 시스템의 안정성과 응답 시간을 평가하기 위해 초당 200명의 유저가 지속적으로 요청을 보내도록 설정되었습니다.
- 예상 트래픽: 목표 TPS는 100 이상으로 설정되며, 초당 최대 100개의 polling 요청이 발생할 수 있는 상황을 시뮬레이션하여 서버의 지속적 부하 처리 능력을 평가합니다.

#### 성능 지표 분석
```text
     execution: local
        script: api-queue-status-test.js
        output: -

     scenarios: (100.00%) 1 scenario, 200 max VUs, 1m30s max duration (incl. graceful stop):
              * default: Up to 200 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


     ✓ status is 200
     ✓ response time < 500ms

     checks.........................: 100.00% 3359600 out of 3359600
     data_received..................: 321 MB  5.4 MB/s
     data_sent......................: 316 MB  5.3 MB/s
     http_req_blocked...............: avg=6.42µs   min=0s       med=1µs    max=68.24ms  p(90)=2µs    p(95)=4µs   
     http_req_connecting............: avg=3.46µs   min=0s       med=0s     max=68.22ms  p(90)=0s     p(95)=0s    
   ✓ http_req_duration..............: avg=554.02µs min=33µs     med=190µs  max=113.4ms  p(90)=958µs  p(95)=1.64ms
       { expected_response:true }...: avg=554.02µs min=33µs     med=190µs  max=113.4ms  p(90)=958µs  p(95)=1.64ms
   ✓ http_req_failed................: 0.00%   0 out of 1679800
     http_req_receiving.............: avg=40.72µs  min=-1000ns  med=5µs    max=84.39ms  p(90)=29µs   p(95)=75µs  
     http_req_sending...............: avg=50.73µs  min=-15000ns med=2µs    max=101.09ms p(90)=56µs   p(95)=143µs 
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s     max=0s       p(90)=0s     p(95)=0s    
     http_req_waiting...............: avg=462.57µs min=25µs     med=155µs  max=95.42ms  p(90)=797µs  p(95)=1.3ms 
     http_reqs......................: 1679800 27993.019176/s
     iteration_duration.............: avg=5.91ms   min=5.05ms   med=5.37ms max=179.05ms p(90)=6.76ms p(95)=8.02ms
     iterations.....................: 1679800 27993.019176/s
     vus............................: 200     min=10                 max=200
     vus_max........................: 200     min=200                max=200
```
- 평균 요청 처리 속도: 약 27,993 requests/sec
- 평균 응답 시간: 0.554ms
- 50번째 백분위수 응답 시간: 190µs
- 95번째 백분위수 응답 시간: 1.64ms
- 최대 응답 시간: 113.4ms

이 시스템은 초당 약 27,993개의 요청을 처리할 수 있으며, 대부분의 요청은 0.5ms 이하로 처리됩니다. 
95%의 요청은 1.64ms 이하로 빠르게 처리되며, 최대 응답 시간도 113.4ms로 처리할 수 있는 범위 내에 있습니다.    
시스템은 매우 높은 처리 능력과 안정성을 가지고 있으며, 고부하 상태에서도 우수한 성능을 보입니다.   

### 3. `GET /api/v1/concert/{concertId}/schedules`: 예약 가능 일정 조회
> 대규모의 유저가 동시에 예약 가능한 날짜 정보를 조회하는 상황을 시뮬레이션하여, 서버의 성능과 응답 속도를 평가하는 것입니다.

#### 테스트 
- 다수의 유저가 특정 콘서트의 예약 가능 날짜를 조회합니다.
- 서버는 각 요청에 대해 200 OK 응답을 보내고, 날짜 정보를 반환합니다.
- 응답 시간과 성능을 평가합니다.

#### 부하 조건
- 유저 수: 초당 10명에서 50명까지 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 예약 가능한 날짜 조회 API는 대량의 데이터를 처리하며, 많은 유저가 동시에 요청할 때 시스템의 응답 시간이 길어질 수 있습니다. 이러한 상황을 시뮬레이션하기 위해 초당 10명에서 50명까지 유저 수를 증가시키는 부하 조건을 설정하여, 시스템의 성능을 평가합니다.
- 예상 트래픽: 목표 TPS는 약 10~50 TPS로 설정되며, 초당 최대 50개의 날짜 조회 요청이 발생할 수 있는 상황을 평가하여 시스템의 데이터 처리 성능을 분석합니다.

#### 성능 지표 분석
```text
     execution: local
        script: api-concert-schedules-test.js
        output: -

     scenarios: (100.00%) 1 scenario, 50 max VUs, 1m30s max duration (incl. graceful stop):
              * default: Up to 50 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


     ✓ status is 200
     ✗ response time < 500ms
      ↳  96% — ✓ 1116 / ✗ 41

     checks.........................: 98.22% 2273 out of 2314
     data_received..................: 2.1 GB 35 MB/s
     data_sent......................: 124 kB 2.0 kB/s
     http_req_blocked...............: avg=24.98µs  min=1µs     med=4µs     max=2.07ms   p(90)=10.4µs   p(95)=42.79µs 
     http_req_connecting............: avg=15.23µs  min=0s      med=0s      max=1.97ms   p(90)=0s       p(95)=0s      
   ✓ http_req_duration..............: avg=151.02ms min=63.27ms med=98.34ms max=956.87ms p(90)=280.31ms p(95)=440.17ms
       { expected_response:true }...: avg=151.02ms min=63.27ms med=98.34ms max=956.87ms p(90)=280.31ms p(95)=440.17ms
   ✓ http_req_failed................: 0.00%  0 out of 1157
     http_req_receiving.............: avg=32.82ms  min=12.48ms med=19.93ms max=362.25ms p(90)=66.58ms  p(95)=99.66ms 
     http_req_sending...............: avg=21.22µs  min=3µs     med=12µs    max=3.24ms   p(90)=29µs     p(95)=44.19µs 
     http_req_tls_handshaking.......: avg=0s       min=0s      med=0s      max=0s       p(90)=0s       p(95)=0s      
     http_req_waiting...............: avg=118.18ms min=47.3ms  med=77.02ms max=816.36ms p(90)=236ms    p(95)=328.12ms
     http_reqs......................: 1157   18.951842/s
     iteration_duration.............: avg=1.15s    min=1.06s   med=1.09s   max=1.95s    p(90)=1.28s    p(95)=1.44s   
     iterations.....................: 1157   18.951842/s
     vus............................: 2      min=1            max=50
     vus_max........................: 50     min=50           max=50
```
- 평균 요청 처리 속도: 약 18.95 requests/sec
- 평균 응답 시간: 151.02ms
- 50번째 백분위수 응답 시간: 98.34ms
- 95번째 백분위수 응답 시간: 약 440.17ms
- 최대 응답 시간: 956.87ms

- 응답 시간 개선 필요: 대부분의 요청이 평균적으로 151.02ms로 처리되었지만, 목표한 500ms 이하의 응답 시간이 달성되지 않았습니다. 특히 95번째 백분위수와 최대 응답 시간에서 응답이 길어지는 경향이 나타났습니다.
- 시스템의 일관성 부족: 50번째 백분위수의 응답 시간은 98.34ms로 빠르지만, 95번째 백분위수가 440.17ms로 상대적으로 길어지는 점에서 성능의 일관성이 떨어집니다. 일부 요청은 최대 956.87ms까지 지연되었으며, 이는 사용자 경험에 부정적인 영향을 미칠 수 있습니다.
- 부하 증가에 대한 대응: 테스트에서는 부하가 낮았기 때문에 성능이 유지될 수 있었지만, 더 많은 트래픽이 유입될 경우 성능이 급격히 저하될 가능성이 존재합니다.
- 대기 시간 문제: http_req_waiting에서 평균 118.18ms, 최대 816.36ms의 대기 시간이 발생했습니다. 이는 서버의 리소스나 병목 현상으로 인해 지연이 발생할 수 있음을 시사합니다.

### 4. `GET /api/v1/concert/{concertId}/schedules/{scheduleId}/seats`: 예약 가능 좌석 조회
> 대규모 유저가 동시에 좌석 정보를 조회할 때, 시스템의 응답 성능과 처리 능력을 평가하기 위한 것입니다. 실시간 데이터 조회에 대한 서버의 처리 능력을 테스트합니다.

#### 테스트 
- 많은 유저가 동시에 특정 콘서트의 좌석 정보를 조회합니다.
- 서버는 좌석 정보 데이터를 반환하며, 각 요청에 대해 200 OK 응답을 보냅니다.
- 응답 시간 및 정확성을 평가합니다.

#### 부하 조건
- 유저 수: 초당 20명에서 80명까지 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 예약 가능 좌석 조회 API는 실시간 데이터를 다루며, 많은 유저가 동시에 좌석 정보를 조회할 때 시스템의 성능이 크게 영향을 받을 수 있습니다. 이러한 상황을 시뮬레이션하기 위해 초당 20명에서 80명까지 유저 수를 증가시키는 부하 조건을 설정하여, 시스템이 급격한 트래픽 증가에 어떻게 반응하는지 평가합니다.
- 예상 트래픽: 목표 TPS는 약 20~50 TPS로 설정하며, 초당 최대 80개의 좌석 조회 요청이 발생할 수 있는 상황을 평가하여 시스템의 처리 성능을 분석합니다.

#### 성능 지표 분석
```text
     execution: local
        script: api-concert-seats-test.js
        output: -

     scenarios: (100.00%) 1 scenario, 80 max VUs, 1m30s max duration (incl. graceful stop):
              * default: Up to 80 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


     ✓ status is 200
     ✓ response time < 500ms

     checks.........................: 100.00% 4456 out of 4456
     data_received..................: 1.1 MB  18 kB/s
     data_sent......................: 256 kB  4.2 kB/s
     http_req_blocked...............: avg=24.94µs min=0s    med=4.5µs max=1.48ms  p(90)=15µs   p(95)=24.64µs
     http_req_connecting............: avg=14.74µs min=0s    med=0s    max=1.06ms  p(90)=0s     p(95)=0s     
   ✓ http_req_duration..............: avg=1.43ms  min=202µs med=806µs max=38.57ms p(90)=2.53ms p(95)=3.7ms  
       { expected_response:true }...: avg=1.43ms  min=202µs med=806µs max=38.57ms p(90)=2.53ms p(95)=3.7ms  
   ✓ http_req_failed................: 0.00%   0 out of 2228
     http_req_receiving.............: avg=58.28µs min=6µs   med=31µs  max=10.66ms p(90)=110µs  p(95)=139µs  
     http_req_sending...............: avg=21.83µs min=2µs   med=12µs  max=1.63ms  p(90)=41µs   p(95)=53µs   
     http_req_tls_handshaking.......: avg=0s      min=0s    med=0s    max=0s      p(90)=0s     p(95)=0s     
     http_req_waiting...............: avg=1.35ms  min=191µs med=753µs max=38.13ms p(90)=2.36ms p(95)=3.49ms 
     http_reqs......................: 2228    36.529527/s
     iteration_duration.............: avg=1s      min=1s    med=1s    max=1.04s   p(90)=1s     p(95)=1s     
     iterations.....................: 2228    36.529527/s
     vus............................: 1       min=1            max=79
     vus_max........................: 80      min=80           max=80
```
- 평균 요청 처리 속도: 36.529 requests/sec
- 평균 응답 시간: 1.43ms
- 50번째 백분위수 응답 시간: 806µs
- 95번째 백분위수 응답 시간: 3.7ms
- 최대 응답 시간: 38.57ms

응답 시간과 실패율이 모두 매우 우수합니다. 시스템이 높은 부하에서도 안정적으로 작동할 것으로 예상됩니다.
이 성능 결과는 대규모 서비스에서 충분히 사용 가능한 수준입니다. 높은 트래픽에도 대응할 수 있을 것으로 보이며, 응답 시간과 오류율 모두 목표를 잘 충족하고 있습니다.

## 가상 장애 대응 상황 설정 및 대응
### API별 100배 부하 설정 가상 시나리오
> 각 API에 대해 예상되는 최대 트래픽의 100배에 달하는 부하를 가정하여, 시스템의 극한 상황에서의 반응을 테스트합니다. 극단적인 고부하 상황에서 발생할 수 있는 병목 구간을 식별하고, 시스템의 안정성 및 성능 개선을 위한 인사이트를 얻습니다.

#### 1. `POST /api/v1/queue/tokens`
- 부하 조건: 초당 5000명의 유저가 대기열 토큰을 생성하는 상황을 시뮬레이션합니다.
- 병목 구간 설정:
  - Redis의 성능 및 확장성:
    - 대기열 토큰 생성 요청을 처리하는 Redis는 대량의 쓰기 작업이 발생할 때 성능 저하가 발생할 수 있습니다. 특히, Redis 클러스터의 노드 간 데이터 분산과 네트워크 대역폭 사용이 병목 현상을 초래할 가능성이 있습니다.
  - 개선 방향
    - Redis 클러스터 확장: Redis 클러스터의 노드 수를 확장하여 데이터 분산과 처리 능력을 향상시킵니다. 클러스터 내 데이터 분산 알고리즘을 재검토하여 부하를 균등하게 분산할 수 있도록 최적화합니다.
    - 쓰기 최적화: Redis의 AOF(Append Only File) 옵션을 최적화하여 쓰기 성능을 향상시키고, 필요 없는 데이터를 주기적으로 삭제하여 메모리 사용량을 줄입니다.

#### 2. `GET /api/v1/queue/status`
- 부하 조건: 초당 20,000명의 유저가 자신의 대기열 상태를 조회하는 상황을 시뮬레이션합니다.
- 병목 구간 식별:
  - Redis의 읽기 성능 및 확장성:
    - 이 API는 대기열 상태를 조회할 때 Redis에서 유저의 위치 정보를 읽어옵니다. 초당 20,000건의 읽기 요청이 발생할 경우, Redis의 처리 능력이 병목이 될 수 있습니다. 읽기 전용 Redis 클러스터를 별도로 구성하거나, 슬레이브 노드 수를 증가시켜 읽기 부하를 분산하는 방안을 고려해야 합니다.
  - 개선 방향
    - 읽기 전용 Redis 클러스터 구성: 읽기 전용 Redis 클러스터를 별도로 구성하여 읽기 부하를 분산시킵니다. 이를 통해 읽기 요청 처리 능력을 향상시키고, 메인 Redis 클러스터의 쓰기 성능에 미치는 영향을 최소화합니다.
    - 슬레이브 노드 추가: 슬레이브 노드를 추가하여 읽기 요청을 슬레이브 노드에서 처리하게 함으로써 Redis의 전반적인 부하를 분산합니다.

#### 3. `GET /api/v1/concert/{concertId}/schedules`
- 부하 조건: 초당 5000명의 유저가 동시에 특정 콘서트의 예약 가능 날짜를 조회하는 상황을 시뮬레이션합니다.
- 병목 구간 설정:
  - 로컬 캐시 문제:
    - 이 API는 로컬 캐시를 사용하여 예약 가능 날짜 정보를 캐싱합니다. 고부하 상황에서는 로컬 캐시가 빠르게 소진될 수 있으며, 캐시 재생성 과정에서 성능 저하가 발생할 수 있습니다. 캐시 TTL 설정 및 크기를 재검토하고, 필요 시 Redis와 같은 외부 캐시 시스템을 사용하는 글로벌 캐시로의 확장을 고려해야 합니다.
    - 개선 방향
      - 캐시 TTL 및 크기 최적화: 로컬 캐시의 TTL 설정을 재검토하여 캐시 갱신 빈도를 줄이고, 캐시 크기를 확장하여 고부하 상황에서도 충분한 데이터를 캐싱할 수 있도록 합니다.
      - 외부 캐시 시스템 도입: 로컬 캐시의 한계를 보완하기 위해 Redis와 같은 외부 캐시 시스템으로 확장하여 캐시 미스로 인한 DB 부하를 줄이고, 전체적인 응답 속도를 향상시킵니다.
      - 캐시 갱신 전략 최적화: 동일한 캐시 키에 대해 다수의 요청이 동시에 발생할 때 성능 저하를 방지하기 위해, 캐시 갱신 시점을 조정하고 데이터 일관성을 유지하면서도 성능을 높일 수 있는 갱신 전략을 도입합니다.

#### 4. `GET /api/v1/concert/{concertId}/schedules/{scheduleId}/seats`
- 부하 조건: 초당 8000명의 유저가 특정 콘서트의 좌석 정보를 조회하는 상황을 시뮬레이션합니다.
- 병목 구간 식별:
  - 데이터베이스 조회 및 인덱스 효율성:
    - 좌석 정보 조회 시 다수의 데이터베이스 조회 작업이 발생하며, 인덱스의 효율성이 중요한 역할을 합니다. 데이터베이스의 쿼리 처리 속도와 인덱스의 적절한 사용이 병목이 될 수 있습니다.
  - 개선 방향
    - 인덱스 최적화: 쿼리 성능을 향상시키기 위해 데이터베이스 인덱스를 최적화합니다. 빈번히 사용되는 쿼리에 대해 추가적인 인덱스를 생성하거나, 기존 인덱스를 재구성하여 조회 속도를 개선합니다.
    - 쿼리 튜닝: 데이터베이스 쿼리를 튜닝하여 필요 없는 조인 및 서브쿼리를 줄이고, 효율적인 쿼리 경로를 사용할 수 있도록 합니다. 또한, 동일한 조회 요청이 반복적으로 발생하는 경우 캐시된 결과를 활용하는 쿼리 캐싱을 도입합니다.